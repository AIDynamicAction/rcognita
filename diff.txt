diff --cc rcognita/controllers.py
index f2759f9,d02ff97..0000000
--- a/rcognita/controllers.py
+++ b/rcognita/controllers.py
@@@ -72,16 -75,15 +76,21 @@@ class CtrlRLStab
      
      ``w_actor`` : weights
      
 -    ``_psi``: regressor
 +    ``_regressor_actor``: regressor
      
++<<<<<<< HEAD
 +    ``_regressor_actor`` is a vector, not a matrix. So, if the environment is multi-input, the input is actually computed as, in case of a 1-layer net,
 +    
 +    ``action = reshape(w_actor, (self.dim_input, self.dim_actor_per_input)) @ self._regressor_actor( observation )``
++=======
+     ``_psi`` is a vector, not a matrix. So, if the environment is multi-input, the input is actually computed as
+     
+     ``u = reshape(w_actor, (self.dim_input, self.dim_actor_per_input)) @ self._psi( y )``
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
      
-     where ``observation`` is the observation or, in other words, output.
+     where ``y`` is the output.
      
-     Actor structure is defined via a string flag ``actor_struct``. Structures are analogous to the critic ones - read more in class description of
-     ``controllers.CtrlOptPred``
+     Actor structure is defined via a string flag ``actor_struct``. Structures are analogous to the critic ones - read more in class description of ``controllers.ctrl_opt_pred``
      
      Critic
      -----
@@@ -105,124 -103,10 +110,131 @@@
      Osinenko, P., Beckenbach, L., GÃ¶hrt, T., & Streif, S. (2020). A reinforcement learning method with closed-loop stability guarantee. IFAC-PapersOnLine  
      
      """
++<<<<<<< HEAD
 +    def __init__(self,
 +                 dim_input,
 +                 dim_output,
 +                 mode='JACS',
 +                 ctrl_bnds=[],
 +                 t0=0,
 +                 sampling_time=0.1,
 +                 Nactor=1,
 +                 pred_step_size=0.1,
 +                 sys_rhs=[],
 +                 sys_out=[],
 +                 state_sys=[],
 +                 prob_noise_pow = 1,
 +                 is_est_model=0,
 +                 model_est_stage=1,
 +                 model_est_period=0.1,
 +                 buffer_size=20,
 +                 model_order=3,
 +                 model_est_checks=0,
 +                 gamma=1,
 +                 Ncritic=4,
 +                 critic_period=0.1,
 +                 critic_struct='quad-nomix',
 +                 actor_struct='quad-nomix',
 +                 rcost_struct='quadratic',
 +                 rcost_pars=[],
 +                 observation_target=[],   
 +                 safe_ctrl=[],
 +                 safe_decay_rate=[]):
 +        
 +        """
 +        Parameters
 +        ----------
 +        dim_input, dim_output : : integer
 +            Dimension of input and output which should comply with the system-to-be-controlled  
 +    
 +        ctrl_bnds : : array of shape ``[dim_input, 2]``
 +            Box control constraints.
 +            First element in each row is the lower bound, the second - the upper bound.
 +            If empty, control is unconstrained (default)
 +        t0 : : number
 +            Initial value of the controller's internal clock
 +        sampling_time : : number
 +            Controller's sampling time (in seconds)
 +        sys_rhs, sys_out : : functions        
 +            Functions that represent the right-hand side, resp., the output of the exogenously passed model.
 +            The latter could be, for instance, the true model of the system.
 +            In turn, ``state_sys`` represents the (true) current state of the system and should be updated accordingly.
 +            Parameters ``sys_rhs, sys_out, state_sys`` are used in those controller modes which rely on them
 +        prob_noise_pow : : number
 +            Power of probing noise during an initial phase to fill the estimator's buffer before applying optimal control   
 +        is_est_model : : number
 +            Flag whether to estimate a system model. See :func:`~controllers.CtrlOptPred._estimate_model` 
 +        model_est_stage : : number
 +            Initial time segment to fill the estimator's buffer before applying optimal control (in seconds)      
 +        model_est_period : : number
 +            Time between model estimate updates (in seconds)
 +        buffer_size : : natural number
 +            Size of the buffer to store data
 +        model_order : : natural number
 +            Order of the state-space estimation model
 +            
 +            .. math::
 +                \\begin{array}{ll}
 +        			\\hat x^+ & = A \\hat x + B u \\newline
 +        			y^+  & = C \\hat x + D u,
 +                \\end{array}             
 +            
 +            See :func:`~controllers.CtrlOptPred._estimate_model`. This is just a particular model estimator.
 +            When customizing, :func:`~controllers.CtrlOptPred._estimate_model` may be changed and in turn the parameter ``model_order`` also. For instance, you might want to use an artifial
 +            neural net and specify its layers and numbers of neurons, in which case ``model_order`` could be substituted for, say, ``Nlayers``, ``Nneurons`` 
 +        model_est_checks : : natural number
 +            Estimated model parameters can be stored in stacks and the best among the ``model_est_checks`` last ones is picked.
 +            May improve the prediction quality somewhat
 +        gamma : : number in (0, 1]
 +            Discounting factor.
 +            Characterizes fading of running costs along horizon
 +        Ncritic : : natural number
 +            Critic stack size :math:`N_c`. The critic optimizes the temporal error which is a measure of critic's ability to capture the
 +            optimal infinite-horizon cost (a.k.a. the value function). The temporal errors are stacked up using the said buffer
 +        critic_period : : number
 +            The same meaning as ``model_est_period`` 
 +        critic_struct, actor_struct : : string
 +            Choice of the structure of the critic's and actor's features
 +            
 +            Currently available:
 +                
 +            .. list-table:: Feature structures
 +               :widths: 10 90
 +               :header-rows: 1
 +        
 +               * - Mode
 +                 - Structure
 +               * - 'quad-lin'
 +                 - Quadratic-linear
 +               * - 'quadratic'
 +                 - Quadratic
 +               * - 'quad-nomix'
 +                 - Quadratic, no mixed terms
 +           
 +            *Add your specification into the table when customizing the actor and critic* 
 +        rcost_struct : : string
 +            Choice of the running cost structure.
 +            
 +            Currently available:
 +               
 +            .. list-table:: Running objective structures
 +               :widths: 10 90
 +               :header-rows: 1
 +        
 +               * - Mode
 +                 - Structure
 +               * - 'quadratic'
 +                 - Quadratic :math:`\\chi^\\top R_1 \\chi`, where :math:`\\chi = [observation, action]`, ``rcost_pars`` should be ``[R1]``
 +               * - 'biquadratic'
 +                 - 4th order :math:`\\left( \\chi^\\top \\right)^2 R_2 \\left( \\chi \\right)^2 + \\chi^\\top R_1 \\chi`, where :math:`\\chi = [observation, action]`, ``rcost_pars``
 +                   should be ``[R1, R2]``
 +        """
++=======
+     def __init__(self, dim_input, dim_output, mode='JACS', ctrl_bnds=[], t0=0, sampling_time=0.1, Nactor=1, pred_step_size=0.1,
+                  sys_rhs=[], sys_out=[], x_sys=[], prob_noise_pow = 1, is_est_model=0, model_est_stage=1, model_est_period=0.1, buffer_size=20, model_order=3, model_est_checks=0,
+                  gamma=1, Ncritic=4, critic_period=0.1, critic_struct='quad-nomix', actor_struct='quad-nomix', rcost_struct='quadratic', rcost_pars=[], y_target=[],
+                  safe_ctrl=[], safe_decay_rate=[]):
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
          
          self.dim_input = dim_input
          self.dim_output = dim_output
@@@ -335,16 -258,16 +347,16 @@@
          
          """
          self.ctrl_clock = t0
-         self.action_curr = self.action_min/10
+         self.uCurr = self.uMin/10
      
 -    def receive_sys_state(self, x):
 +    def receive_sys_state(self, state):
          """
          Fetch exogenous model state. Used in some controller modes. See class documentation
  
          """
 -        self.x_sys = x
 +        self.state_sys = state
      
-     def rcost(self, observation, action):
+     def rcost(self, y, u):
          """
          Running cost (a.k.a. utility, reward, instantaneous cost etc.)
          
@@@ -374,17 -297,17 +386,21 @@@
          The smaller, the better (depends on the problem specification of course - you might want to maximize cost instead)
          
          """
-         self.icost_val += self.rcost(observation, action)*self.sampling_time
+         self.icost_val += self.rcost(y, u)*self.sampling_time
  
++<<<<<<< HEAD
 +    def _regressor_critic(self, observation):
++=======
+     def _phi(self, y):
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
          """
-         Features of the critic
+         Feature vector of the critic
  
          """
-         if self.observation_target == []:
-             chi = observation
+         if self.y_target == []:
+             chi = y
          else:
-             chi = observation - self.observation_target
+             chi = y - self.y_target
          
          if self.critic_struct == 'quad-lin':
              return np.concatenate([ uptria2vec( np.outer(chi, chi) ), chi ])
@@@ -393,9 -316,9 +409,13 @@@
          elif self.critic_struct == 'quad-nomix':
              return chi * chi
          
++<<<<<<< HEAD
 +    def _regressor_actor(self, observation):
++=======
+     def _psi(self, y):
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
          """
-         Features of the actor
+         Feature vector of the actor
  
          """
  
@@@ -414,25 -337,25 +434,39 @@@
         
          """        
          
++<<<<<<< HEAD
 +        observation_sqn = self.observation_buffer[-self.Ncritic:,:]
++=======
+         Y = self.ybuffer[-self.Ncritic:,:]
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
          
-         w_critic = w_all[:self.dim_critic]
+         w_critic = W_lmbd_u[:self.dim_critic]
          # lmbd = W_lmbd_u[self.dim_critic+1]
-         w_actor = w_all[-self.dim_actor:]         
+         w_actor = W_lmbd_u[-self.dim_actor:]         
          
          Jc = 0
          
          for k in range(self.Ncritic-1, 0, -1):
++<<<<<<< HEAD
 +            observation_prev = observation_sqn[k-1, :]
 +            observation_next = observation_sqn[k, :]
 +            
 +            critic_prev = w_critic @ self._regressor_critic( observation_prev )
 +            critic_next = self.w_critic_prev @ self._regressor_critic( observation_next )
 +            
 +            action = reshape(w_actor, (self.dim_input, self.dim_actor_per_input)) @ self._regressor_actor( observation_prev )
++=======
+             yPrev = Y[k-1, :]
+             yNext = Y[k, :]
+             
+             critic_prev = w_critic @ self._phi( yPrev )
+             critic_next = self.w_critic_prev @ self._phi( yNext )
+             
+             u = reshape(w_actor, (self.dim_input, self.dim_actor_per_input)) @ self._psi( yPrev )
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
              
              # Temporal difference
-             e = critic_prev - self.gamma * critic_next - self.rcost(observation_prev, action)
+             e = critic_prev - self.gamma * critic_next - self.rcost(yPrev, u)
              
              Jc += 1/2 * e**2
          
@@@ -452,8 -375,8 +486,13 @@@
              w_critic = w_all[:self.dim_critic]
              lmbd = w_all[self.dim_critic]
              
++<<<<<<< HEAD
 +            critic_curr = self.lmbd_prev * self.w_critic_prev @ self._regressor_critic( observation ) + ( 1 - self.lmbd_prev ) * self.safe_ctrl.compute_LF( observation )
 +            critic_new = lmbd * w_critic @ self._regressor_critic( observation ) + ( 1 - lmbd ) * self.safe_ctrl.compute_LF( observation )
++=======
+             critic_curr = self.lmbd_prev * self.w_critic_prev @ self._phi( y ) + ( 1 - self.lmbd_prev ) * self.safe_ctrl.compute_LF(y)
+             critic_new = lmbd * w_critic @ self._phi( y ) + ( 1 - lmbd ) * self.safe_ctrl.compute_LF(y)
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
              
              return critic_new - critic_curr
              
@@@ -462,25 -385,25 +501,42 @@@
              lmbd = w_all[self.dim_critic]
              w_actor = w_all[-self.dim_actor:] 
                          
++<<<<<<< HEAD
 +            action = reshape(w_actor, (self.dim_input, self.dim_actor_per_input)) @ self._regressor_actor( observation )
++=======
+             u = reshape(w_actor, (self.dim_input, self.dim_actor_per_input)) @ self._psi( y )
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
              
-             observation_next = observation + self.pred_step_size * self.sys_rhs([], observation, action)  # Euler scheme
+             y_next = y + self.pred_step_size * self.sys_rhs([], y, u)  # Euler scheme
              
++<<<<<<< HEAD
 +            critic_next = lmbd * w_critic @ self._regressor_critic( observation_next ) + ( 1 - lmbd ) * self.safe_ctrl.compute_LF( observation_next )
++=======
+             critic_next = lmbd * w_critic @ self._phi( y_next ) + ( 1 - lmbd ) * self.safe_ctrl.compute_LF( y_next )
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
              
-             return self.safe_ctrl.compute_LF(observation_next) - critic_next        
+             return self.safe_ctrl.compute_LF(y_next) - critic_next        
          
-         def constr_stab_decay(w_all, observation):
+         def constr_stab_decay(w_all, y):
              w_critic = w_all[:self.dim_critic]
              lmbd = w_all[self.dim_critic]
              w_actor = w_all[-self.dim_actor:]   
              
++<<<<<<< HEAD
 +            action = reshape(w_actor, (self.dim_input, self.dim_actor_per_input)) @ self._regressor_actor( observation )
++=======
+             u = reshape(w_actor, (self.dim_input, self.dim_actor_per_input)) @ self._psi( y )
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
              
-             observation_next = observation + self.pred_step_size * self.sys_rhs([], observation, action)  # Euler scheme
+             y_next = y + self.pred_step_size * self.sys_rhs([], y, u)  # Euler scheme
              
++<<<<<<< HEAD
 +            critic_new = lmbd * w_critic @ self._regressor_critic( observation ) + ( 1 - lmbd ) * self.safe_ctrl.compute_LF( observation )
 +            critic_next = lmbd * w_critic @ self._regressor_critic( observation_next ) + ( 1 - lmbd ) * self.safe_ctrl.compute_LF( observation_next )
++=======
+             critic_new = lmbd * w_critic @ self._phi( y ) + ( 1 - lmbd ) * self.safe_ctrl.compute_LF(y)
+             critic_next = lmbd * w_critic @ self._phi( y_next ) + ( 1 - lmbd ) * self.safe_ctrl.compute_LF( y_next )
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
              
              return critic_next - critic_new + self.safe_decay_rate
  
@@@ -488,7 -411,7 +544,11 @@@
              w_critic = w_all[:self.dim_critic]
              lmbd = w_all[self.dim_critic]
              
++<<<<<<< HEAD
 +            critic_new = lmbd * w_critic @ self._regressor_critic( observation ) + ( 1 - lmbd ) * self.safe_ctrl.compute_LF( observation )
++=======
+             critic_new = lmbd * w_critic @ self._phi( y ) + ( 1 - lmbd ) * self.safe_ctrl.compute_LF(y)
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
              
              return - critic_new
  
@@@ -520,12 -443,11 +580,16 @@@
              opt_options = {'maxiter': 10, 'maxfev': 10, 'disp': False, 'adaptive': True, 'xatol': 1e-4, 'fatol': 1e-4} # 'disp': True, 'verbose': 2} 
          
          # Bounds are not practically necessary for stabilizing joint actor-critic to function
-         # bnds = sp.optimize.Bounds(np.hstack([self.w_critic_min, self.lmbd_min, self.Hmin]), 
-         #                           np.hstack([self.w_critic_max, self.lmbd_max, self.Hmax]), 
+         # bnds = sp.optimize.Bounds(np.hstack([self.Wmin, self.lmbd_min, self.Hmin]), 
+         #                           np.hstack([self.Wmax, self.lmbd_max, self.Hmax]), 
          #                           keep_feasible=True)
          
++<<<<<<< HEAD
 +        self.w_actor_init = reshape(lstsq( np.array( [ self._regressor_actor( observation ) ] ),
 +                                           np.array( [ self.safe_ctrl.compute_action_vanila( observation ) ] ) )[0].T, self.dim_actor )
++=======
+         self.Hinit = reshape( lstsq( np.array( [ self._psi( y ) ] ), np.array( [ self.safe_ctrl.compute_action_vanila(y) ] ) )[0].T, self.dim_actor )
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
         
          # DEBUG ===================================================================
          # ================================Constraint debugger
@@@ -536,12 -458,12 +600,16 @@@
          # lmbd = w_all[self.dim_critic]
          # w_actor = w_all[-self.dim_actor:] 
                      
++<<<<<<< HEAD
 +        # action = reshape(w_actor, (self.dim_input, self.dim_actor_per_input)) @ self._regressor_actor( observation )
++=======
+         # u = reshape(w_actor, (self.dim_input, self.dim_actor_per_input)) @ self._psi( y )
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
          
-         # constr_stab_par_decay(w_all, observation)
-         # constr_stab_LF_bound(w_all, observation)
-         # constr_stab_decay(w_all, observation)
-         # constr_stab_positive(w_all, observation)
+         # constr_stab_par_decay(w_all, y)
+         # constr_stab_LF_bound(w_all, y)
+         # constr_stab_decay(w_all, y)
+         # constr_stab_positive(w_all, y)
  
          # /DEBUG ===================================================================         
          
@@@ -559,7 -481,7 +627,11 @@@
          lmbd = w_all[self.dim_critic]
          w_actor = w_all[-self.dim_actor:]       
          
++<<<<<<< HEAD
 +        action = reshape(w_actor, (self.dim_input, self.dim_actor_per_input)) @ self._regressor_actor( observation )       
++=======
+         u = reshape(w_actor, (self.dim_input, self.dim_actor_per_input)) @ self._psi( y )       
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
          
          # DEBUG ===================================================================   
          # ================================Constraint debugger
@@@ -580,8 -502,8 +652,13 @@@
                  
              w_critic = self.w_critic_init
              lmbd = self.lmbd_init
++<<<<<<< HEAD
 +            action = self.safe_ctrl.compute_action_vanila( observation )
 +            w_actor = reshape( lstsq( np.array( [ self._regressor_actor( observation ) ] ), np.array( [ action ] ) )[0].T, self.dim_actor )
++=======
+             u = self.safe_ctrl.compute_action_vanila(y)
+             w_actor = reshape( lstsq( np.array( [ self._psi( y ) ] ), np.array( [ u ] ) )[0].T, self.dim_actor )
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
         
          # DEBUG ===================================================================   
          # ================================Put safe controller through        
@@@ -769,145 -691,9 +846,151 @@@ class CtrlOptPred
          
      """    
           
++<<<<<<< HEAD
 +    def __init__(self,
 +                 dim_input,
 +                 dim_output,
 +                 mode='MPC',
 +                 ctrl_bnds=[],
 +                 t0=0,
 +                 sampling_time=0.1,
 +                 Nactor=1,
 +                 pred_step_size=0.1,
 +                 sys_rhs=[],
 +                 sys_out=[],
 +                 state_sys=[],
 +                 prob_noise_pow = 1,
 +                 is_est_model=0,
 +                 model_est_stage=1,
 +                 model_est_period=0.1,
 +                 buffer_size=20,
 +                 model_order=3,
 +                 model_est_checks=0,
 +                 gamma=1,
 +                 Ncritic=4,
 +                 critic_period=0.1,
 +                 critic_struct='quad-nomix',
 +                 rcost_struct='quadratic',
 +                 rcost_pars=[],
 +                 observation_target=[]):
 +        """
 +        Parameters
 +        ----------
 +        dim_input, dim_output : : integer
 +            Dimension of input and output which should comply with the system-to-be-controlled
 +        mode : : string
 +            Controller mode. Currently available (:math:`r` is the running cost, :math:`\\gamma` is the discounting factor):
 +              
 +            .. list-table:: Controller modes
 +               :widths: 75 25
 +               :header-rows: 1
 +        
 +               * - Mode
 +                 - Cost function
 +               * - 'MPC' - Model-predictive control (MPC)
 +                 - :math:`J \\left( y_1, \\{u\\}_1^{N_a} \\right)=\\sum_{k=1}^{N_a} \\gamma^{k-1} r(y_k, u_k)`
 +               * - 'RQL' - RL/ADP via :math:`N_a-1` roll-outs of :math:`r`
 +                 - :math:`J \\left( y_1, \\{u\}_{1}^{N_a}\\right) =\\sum_{k=1}^{N_a-1} \\gamma^{k-1} r(y_k, u_k) + \\hat Q(y_{N_a}, u_{N_a})` 
 +               * - 'SQL' - RL/ADP via stacked Q-learning [[1]_]
 +                 - :math:`J \\left( y_1, \\{u\\}_1^{N_a} \\right) =\\frac{1}{N_a} \\sum_{k=1}^{N_a-1} \\hat Q(y_{N_a}, u_{N_a})`               
 +            
 +            *Add your specification into the table when customizing the agent*    
 +    
 +        ctrl_bnds : : array of shape ``[dim_input, 2]``
 +            Box control constraints.
 +            First element in each row is the lower bound, the second - the upper bound.
 +            If empty, control is unconstrained (default)
 +        t0 : : number
 +            Initial value of the controller's internal clock
 +        sampling_time : : number
 +            Controller's sampling time (in seconds)
 +        Nactor : : natural number
 +            Size of prediction horizon :math:`N_a` 
 +        pred_step_size : : number
 +            Prediction step size in :math:`J` as defined above (in seconds). Should be a multiple of ``sampling_time``. Commonly, equals it, but here left adjustable for
 +            convenience. Larger prediction step size leads to longer factual horizon
 +        sys_rhs, sys_out : : functions        
 +            Functions that represent the right-hand side, resp., the output of the exogenously passed model.
 +            The latter could be, for instance, the true model of the system.
 +            In turn, ``state_sys`` represents the (true) current state of the system and should be updated accordingly.
 +            Parameters ``sys_rhs, sys_out, state_sys`` are used in those controller modes which rely on them
 +        prob_noise_pow : : number
 +            Power of probing noise during an initial phase to fill the estimator's buffer before applying optimal control   
 +        is_est_model : : number
 +            Flag whether to estimate a system model. See :func:`~controllers.CtrlOptPred._estimate_model` 
 +        model_est_stage : : number
 +            Initial time segment to fill the estimator's buffer before applying optimal control (in seconds)      
 +        model_est_period : : number
 +            Time between model estimate updates (in seconds)
 +        buffer_size : : natural number
 +            Size of the buffer to store data
 +        model_order : : natural number
 +            Order of the state-space estimation model
 +            
 +            .. math::
 +                \\begin{array}{ll}
 +        			\\hat x^+ & = A \\hat x + B u \\newline
 +        			y^+  & = C \\hat x + D u,
 +                \\end{array}             
 +            
 +            See :func:`~controllers.CtrlOptPred._estimate_model`. This is just a particular model estimator.
 +            When customizing, :func:`~controllers.CtrlOptPred._estimate_model` may be changed and in turn the parameter ``model_order`` also. For instance, you might want to use an artifial
 +            neural net and specify its layers and numbers of neurons, in which case ``model_order`` could be substituted for, say, ``Nlayers``, ``Nneurons`` 
 +        model_est_checks : : natural number
 +            Estimated model parameters can be stored in stacks and the best among the ``model_est_checks`` last ones is picked.
 +            May improve the prediction quality somewhat
 +        gamma : : number in (0, 1]
 +            Discounting factor.
 +            Characterizes fading of running costs along horizon
 +        Ncritic : : natural number
 +            Critic stack size :math:`N_c`. The critic optimizes the temporal error which is a measure of critic's ability to capture the
 +            optimal infinite-horizon cost (a.k.a. the value function). The temporal errors are stacked up using the said buffer
 +        critic_period : : number
 +            The same meaning as ``model_est_period`` 
 +        critic_struct : : natural number
 +            Choice of the structure of the critic's features
 +            
 +            Currently available:
 +                
 +            .. list-table:: Critic feature structures
 +               :widths: 10 90
 +               :header-rows: 1
 +        
 +               * - Mode
 +                 - Structure
 +               * - 'quad-lin'
 +                 - Quadratic-linear
 +               * - 'quadratic'
 +                 - Quadratic
 +               * - 'quad-nomix'
 +                 - Quadratic, no mixed terms
 +               * - 'quad-mix'
 +                 - Quadratic, no mixed terms in input and output, i.e., :math:`w_1 y_1^2 + \\dots w_p y_p^2 + w_{p+1} y_1 u_1 + \\dots w_{\\bullet} u_1^2 + \\dots`, 
 +                   where :math:`w` is the critic's weights
 +           
 +            *Add your specification into the table when customizing the critic* 
 +        rcost_struct : : string
 +            Choice of the running cost structure.
 +            
 +            Currently available:
 +               
 +            .. list-table:: Running objective structures
 +               :widths: 10 90
 +               :header-rows: 1
 +        
 +               * - Mode
 +                 - Structure
 +               * - 'quadratic'
 +                 - Quadratic :math:`\\chi^\\top R_1 \\chi`, where :math:`\\chi = [observation, action]`, ``rcost_pars`` should be ``[R1]``
 +               * - 'biquadratic'
 +                 - 4th order :math:`\\left( \\chi^\\top \\right)^2 R_2 \\left( \\chi \\right)^2 + \\chi^\\top R_1 \\chi`, where :math:`\\chi = [observation, action]`, ``rcost_pars``
 +                   should be ``[R1, R2]``
 +        """
++=======
+     def __init__(self, dim_input, dim_output, mode='MPC', ctrl_bnds=[], t0=0, sampling_time=0.1, Nactor=1, pred_step_size=0.1,
+                  sys_rhs=[], sys_out=[], x_sys=[], prob_noise_pow = 1, is_est_model=0, model_est_stage=1, model_est_period=0.1, buffer_size=20, model_order=3, model_est_checks=0,
+                  gamma=1, Ncritic=4, critic_period=0.1, critic_struct='quad-nomix', rcost_struct='quadratic', rcost_pars=[], y_target=[]):
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
          
          self.dim_input = dim_input
          self.dim_output = dim_output
@@@ -1004,16 -829,16 +1087,16 @@@
          
          """
          self.ctrl_clock = t0
-         self.action_curr = self.action_min/10
+         self.uCurr = self.uMin/10
      
 -    def receive_sys_state(self, x):
 +    def receive_sys_state(self, state):
          """
          Fetch exogenous model state. Used in some controller modes. See class documentation
  
          """
 -        self.x_sys = x
 +        self.state_sys = state
      
-     def rcost(self, observation, action):
+     def rcost(self, y, u):
          """
          Running cost (a.k.a. utility, reward, instantaneous cost etc.)
          
@@@ -1157,24 -982,24 +1240,33 @@@
                      # Drop probing noise
                      self.is_prob_noise = 0 
  
++<<<<<<< HEAD
 +    def _regressor_critic(self, observation, action):
++=======
+     def _phi(self, y, u):
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
          """
-         Features of the critic
+         Feature vector of the critic
          
-         In Q-learning mode, it uses both ``observation`` and ``action``. In value function approximation mode, it should use just ``observation``
+         In Q-learning mode, it uses both ``y`` and ``u``. In value function approximation mode, it should use just ``y``
          
          Customization
          -------------
          
          Adjust this method if you still sitck with a linearly parametrized approximator for Q-function, value function etc.
++<<<<<<< HEAD
 +        If you decide to switch to a non-linearly parametrized approximator, you need to alter the terms like ``w_critic @ self._regressor_critic( observation, action )`` 
 +        within :func:`~controllers.CtrlOptPred._critic_cost`
++=======
+         If you decide to switch to a non-linearly parametrized approximator, you need to alter the terms like ``w_critic @ self._phi( y, u )`` 
+         within :func:`~controllers.ctrl_opt_pred._critic_cost`
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
          
          """
-         if self.observation_target == []:
-             chi = np.concatenate([observation, action])
+         if self.y_target == []:
+             chi = np.concatenate([y, u])
          else:
-             chi = np.concatenate([observation - self.observation_target, action])
+             chi = np.concatenate([y - self.y_target, u])
          
          if self.critic_struct == 'quad-lin':
              return np.concatenate([ uptria2vec( np.outer(chi, chi) ), chi ])
@@@ -1200,15 -1025,13 +1292,19 @@@
          Jc = 0
          
          for k in range(self.Ncritic-1, 0, -1):
-             observation_prev = self.observation_buffer[k-1, :]
-             observation_next = self.observation_buffer[k, :]
-             uPrev = self.action_buffer[k-1, :]
-             uNext = self.action_buffer[k, :]
+             yPrev = self.ybuffer[k-1, :]
+             yNext = self.ybuffer[k, :]
+             uPrev = self.ubuffer[k-1, :]
+             uNext = self.ubuffer[k, :]
              
              # Temporal difference
++<<<<<<< HEAD
 +            e = w_critic @ self._regressor_critic( observation_prev, uPrev )- \
 +            self.gamma * self.w_critic_prev @ self._regressor_critic( observation_next, uNext )- \
 +            self.rcost(observation_prev, uPrev)
++=======
+             e = w_critic @ self._phi( yPrev, uPrev ) - self.gamma * self.w_critic_prev @ self._phi( yNext, uNext ) - self.rcost(yPrev, uPrev)
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
              
              Jc += 1/2 * e**2
              
@@@ -1240,7 -1063,7 +1336,11 @@@
          
          return w_critic
      
++<<<<<<< HEAD
 +    def _actor_cost(self, action_sqn, observation):
++=======
+     def _actor_cost(self, U, y):
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
          """
          See class documentation
          
@@@ -1257,18 -1080,18 +1357,29 @@@
          
          # System output prediction
          if not self.is_est_model:    # Via exogenously passed model
++<<<<<<< HEAD
 +            observation_sqn[0, :] = observation
 +            state = self.state_sys
++=======
+             Y[0, :] = y
+             x = self.x_sys
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
              for k in range(1, self.Nactor):
 -                # x = get_next_state(x, myU[k-1, :], delta)         TODO
 -                x = x + self.pred_step_size * self.sys_rhs([], x, myU[k-1, :])  # Euler scheme
 +                # state = get_next_state(state, my_action_sqn[k-1, :], delta)         TODO
 +                state = state + self.pred_step_size * self.sys_rhs([], state, my_action_sqn[k-1, :])  # Euler scheme
                  
 -                Y[k, :] = self.sys_out(x)
 +                observation_sqn[k, :] = self.sys_out(state)
  
          elif self.is_est_model:    # Via estimated model
++<<<<<<< HEAD
 +            my_action_sqn_upsampled = my_action_sqn.repeat(int(self.pred_step_size/self.sampling_time), axis=0)
 +            observation_sqn_upsampled, _ = dss_sim(self.my_model.A, self.my_model.B, self.my_model.C, self.my_model.D, my_action_sqn_upsampled, self.my_model.x0est, observation)
 +            observation_sqn = observation_sqn_upsampled[::int(self.pred_step_size/self.sampling_time)]
++=======
+             myU_upsampled = myU.repeat(int(self.pred_step_size/self.sampling_time), axis=0)
+             Yupsampled, _ = dss_sim(self.my_model.A, self.my_model.B, self.my_model.C, self.my_model.D, myU_upsampled, self.my_model.x0est, y)
+             Y = Yupsampled[::int(self.pred_step_size/self.sampling_time)]
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
          
          J = 0         
          if self.mode=='MPC':
@@@ -1319,14 -1142,14 +1430,19 @@@
              
          #     # System output prediction
          #     if (mode==1) or (mode==3) or (mode==5):    # Via exogenously passed model
++<<<<<<< HEAD
 +        #         observation_sqn[0, :] = observation
 +        #         state = self.state_sys
++=======
+         #         Y[0, :] = y
+         #         x = self.x_sys
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
          #         for k in range(1, idx):
 -        #             # x = get_next_state(x, myU[k-1, :], delta)
 -        #             x = x + delta * self.sys_rhs([], x, myU[k-1, :], [])  # Euler scheme
 -        #             Y[k, :] = self.sys_out(x)            
 +        #             # state = get_next_state(state, my_action_sqn[k-1, :], delta)
 +        #             state = state + delta * self.sys_rhs([], state, my_action_sqn[k-1, :], [])  # Euler scheme
 +        #             observation_sqn[k, :] = self.sys_out(state)            
              
 -        #     return Y[-1, 1] - 1
 +        #     return observation_sqn[-1, 1] - 1
  
          # my_constraints=[]
          # for my_idx in range(1, self.Nactor+1):
@@@ -1345,17 -1168,16 +1461,27 @@@
         
          isGlobOpt = 0
          
++<<<<<<< HEAD
 +        my_action_sqn_init = np.reshape(self.action_sqn_init, [self.Nactor*self.dim_input,])
++=======
+         myUinit = np.reshape(self.Uinit, [self.Nactor*self.dim_input,])
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
          
-         bnds = sp.optimize.Bounds(self.action_sqn_min, self.action_sqn_max, keep_feasible=True)
+         bnds = sp.optimize.Bounds(self.Umin, self.Umax, keep_feasible=True)
          
          try:
              if isGlobOpt:
                  minimizer_kwargs = {'method': actor_opt_method, 'bounds': bnds, 'tol': 1e-7, 'options': actor_opt_options}
++<<<<<<< HEAD
 +                action_sqn = basinhopping(lambda action_sqn: self._actor_cost(action_sqn, observation), my_action_sqn_init, minimizer_kwargs=minimizer_kwargs, niter = 10).x
 +            else:
 +                action_sqn = minimize(lambda action_sqn: self._actor_cost(action_sqn, observation), my_action_sqn_init,
 +                                      method=actor_opt_method, tol=1e-7, bounds=bnds, options=actor_opt_options).x        
++=======
+                 U = basinhopping(lambda U: self._actor_cost(U, y), myUinit, minimizer_kwargs=minimizer_kwargs, niter = 10).x
+             else:
+                 U = minimize(lambda U: self._actor_cost(U, y), myUinit, method=actor_opt_method, tol=1e-7, bounds=bnds, options=actor_opt_options).x        
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
  
          except ValueError:
              print('Actor''s optimizer failed. Returning default action')
@@@ -1365,16 -1187,16 +1491,26 @@@
          # ================================Interm output of model prediction quality
          # R  = '\033[31m'
          # Bl  = '\033[30m'
++<<<<<<< HEAD
 +        # my_action_sqn = np.reshape(action_sqn, [N, self.dim_input])    
 +        # my_action_sqn_upsampled = my_action_sqn.repeat(int(delta/self.sampling_time), axis=0)
 +        # observation_sqn_upsampled, _ = dss_sim(self.my_model.A, self.my_model.B, self.my_model.C, self.my_model.D, my_action_sqn_upsampled, self.my_model.x0est, observation)
 +        # observation_sqn = observation_sqn_upsampled[::int(delta/self.sampling_time)]
 +        # Yt = np.zeros([N, self.dim_output])
 +        # Yt[0, :] = observation
 +        # state = self.state_sys
++=======
+         # myU = np.reshape(U, [N, self.dim_input])    
+         # myU_upsampled = myU.repeat(int(delta/self.sampling_time), axis=0)
+         # Yupsampled, _ = dss_sim(self.my_model.A, self.my_model.B, self.my_model.C, self.my_model.D, myU_upsampled, self.my_model.x0est, y)
+         # Y = Yupsampled[::int(delta/self.sampling_time)]
+         # Yt = np.zeros([N, self.dim_output])
+         # Yt[0, :] = y
+         # x = self.x_sys
++>>>>>>> 047fdb825fdc2717b0010ab762c6e6ab16e249fd
          # for k in range(1, Nactor):
 -        #     x = x + delta * self.sys_rhs([], x, myU[k-1, :], [])  # Euler scheme
 -        #     Yt[k, :] = self.sys_out(x)           
 +        #     state = state + delta * self.sys_rhs([], state, my_action_sqn[k-1, :], [])  # Euler scheme
 +        #     Yt[k, :] = self.sys_out(state)           
          # headerRow = ['diff y1', 'diff y2', 'diff y3', 'diff y4', 'diff y5']  
          # dataRow = []
          # for k in range(dim_output):
@@@ -1384,9 -1206,9 +1520,9 @@@
          # print(R+table+Bl)
          # /DEBUG ==================================================================     
          
 -        return U[:self.dim_input]    # Return first action
 +        return action_sqn[:self.dim_input]    # Return first action
                      
-     def compute_action(self, t, observation):
+     def compute_action(self, t, y):
          """
          Main method. See class documentation
          
